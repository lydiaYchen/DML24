# DML

:warning: **I am still developing the course content. The content will be only be finalized by the end of the first week of the semester.**


This repository contains the materials of the  **Seminar Distributed Machine Learning Systems** - fall 2023  at UniNE . 


##  <a name='Importantlinks'></a>Important links

- [Paper Reading List](PaperList.md)
- [Review template](review.md)




##  <a name='Coursedescription'></a>Course description

Machine learning systems are often conventionally designed for centralized processing in that they first collect data from distributed sources and then execute algorithms on a single server. Due to the limited scalability of processing large amount of data and the long latency delay, there is a strong demand for a paradigm shift to distributed or decentralized ML systems which execute ML algorithms on multiple and in some cases even geographically dispersed nodes.

The aim of this seminar course is to let students learn how to design and build distributed ML systems via paper reading, presentation, and discussion; We provide a broad overview on the design of the state-of-the-art distributed ML systems, with a strong focus on the scalability, resource efficiency, data requirements, and robustness of the solutions. We will present an array of methodologies and techniques that can efficiently scale ML analysis to a large number of distributed nodes against all operation conditions, e.g., system failures and malicious attacks. The specific course topics are listed below.

The course materials will be based on a mixture of classic and recently published papers. The first 3-4 lectures, the basic concept of distributed machine learning will be covered, followed by three weeks of self-study time, and then student presentations will be given.



##  <a name='Paper List'></a>Mandatory Paper Reviews


Paper reading and reviews are the key activities in this course. To pass the course, you need to 
- Submit at least 4 reviewers on 4 different topics out of 6 topics.
- Present at least one paper out of 6 topics during the second half of the course.
- All reviews need to be submitted to the ILIAS by the last week of the semester.


Check [Paper Reading List](PaperList.md)



##  <a name='Courseteam'></a>Course team
This course will be mainly taught by [Prof. Lydia Y Chen]([https://lydiaychen.github.io/]) . The course team is composed of a number of PhDs  who support the course through guest lectures.



Lydia can be alwasy reached at **lydiaychen@ieee.org**. In order to get prompt response about the course, put the email title starting with [DML23]

[//]: # (5. <a name='ECs'></a>ECs)

[//]: # (This is a **5 EC course**, with **140 hours** of course work in total. We expect you to spread the load evenly across the 9 course weeks.)

##  <a name='Learningobjectives'></a>Learning objectives
- To argue and reason about distributed ML from a systems perspective.
- To understand the behavior and tradeoffs of distributed ML in terms of performance and scalability
- To estimate the importance of data inputs via different techniques, i.e., core set and decomposition methods, for distributed ML systems.
- To understand data poison attacks and design defense strategy for distributed ML systems.
- To analyze the state-of-the art federated machine learning systems and design the failure-resilient communication protocols
- To design and implement methods and techniques for making distributed ML systems more efficient.
- 



**All assessment items (reviews and presentation slides) have to be submitted via ILIAS.**

To pass the course, you need to
1. Submmit at least 4 paper reviews (template and requirement can be found [here](review.md) )
2. Present at least 1 paper (30 minutes plus Q/A)

##  <a name='Detailedschedule'></a>Detailed schedule


**Week**|**Topic**
:-----|:-----
Week 1 | Distributed Machine Learning I |
Week 2 | Fedearted Machine Learning II
Week 3| Self-study
Week 4| Aceeleration
Week 5| Self study
Week 6| Self study
Week 7| Self study
Week 8| Self study
Week 9| Paper presentation and discussion on topic 1-6
Week 10|Paper presentation and discussion on topic 1-6
Week 11| Paper presentation and discussion on topic 1-6
Week 12| Paper presentation and discussion on topic 1-6
Week 13| Paper presentation and discussion on topic 1-6

